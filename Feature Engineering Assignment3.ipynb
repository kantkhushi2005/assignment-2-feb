{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "432b133f-22b0-45ec-80e0-43b3de384e6d",
   "metadata": {},
   "source": [
    "Q1. What is Min-Max scaling, and how is it used in data preprocessing? Provide an example to illustrate its\n",
    "application.\n",
    "\n",
    "\n",
    "Min-Max scaling is a data preprocessing technique that transforms features to a common scale, usually [0, 1]. It is used to normalize features to improve the performance of machine learning algorithms, especially those sensitive to the scale of data like gradient descent-based models.\n",
    "\n",
    "**Formula:** \\[ X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}} \\]\n",
    "\n",
    "**Example:**\n",
    "Suppose you have a feature \"Age\" with values ranging from 20 to 60. To scale it to [0, 1]:\n",
    "1. **Original Age Value:** 30\n",
    "2. **Min Value (X_min):** 20\n",
    "3. **Max Value (X_max):** 60\n",
    "\n",
    "Applying Min-Max scaling:\n",
    "\\[ \\text{Scaled Age} = \\frac{30 - 20}{60 - 20} = \\frac{10}{40} = 0.25 \\]\n",
    "\n",
    "So, the scaled value of age 30 is 0.25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecf99e7-e250-4d59-bf64-cbbba13195e5",
   "metadata": {},
   "source": [
    "Q2. What is the Unit Vector technique in feature scaling, and how does it differ from Min-Max scaling?\n",
    "Provide an example to illustrate its application.\n",
    "\n",
    "The Unit Vector technique, also known as normalization or vector normalization, scales features to a unit vector (length of 1). It transforms data into a space where the magnitude of the vector for each sample is 1, which is useful for algorithms that rely on the distance between data points, like K-nearest neighbors.\n",
    "\n",
    "**Formula:** \\[ \\text{Normalized Vector} = \\frac{\\mathbf{X}}{\\|\\mathbf{X}\\|} \\]\n",
    "where \\(\\|\\mathbf{X}\\|\\) is the Euclidean norm of the vector \\(\\mathbf{X}\\).\n",
    "\n",
    "**Example:**\n",
    "Suppose you have a feature vector \\([3, 4]\\).\n",
    "\n",
    "1. **Calculate the Euclidean norm:** \\(\\|\\mathbf{X}\\| = \\sqrt{3^2 + 4^2} = \\sqrt{25} = 5\\)\n",
    "2. **Normalize the vector:** \\(\\frac{[3, 4]}{5} = [0.6, 0.8]\\)\n",
    "\n",
    "**Difference from Min-Max Scaling:**\n",
    "- **Min-Max Scaling:** Transforms features to a fixed range [0, 1].\n",
    "- **Unit Vector Normalization:** Scales data to have unit length (magnitude of 1), preserving the direction but changing the scale. \n",
    "\n",
    "Min-Max Scaling is about scaling to a specific range, while Unit Vector Normalization is about adjusting the length of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e1a4a9-2b06-4226-93d6-bbd49702d037",
   "metadata": {},
   "source": [
    "Q3. What is PCA (Principle Component Analysis), and how is it used in dimensionality reduction? Provide an\n",
    "example to illustrate its application.\n",
    "\n",
    "Principal Component Analysis (PCA) is a dimensionality reduction technique that transforms data into a new coordinate system where the greatest variance by any projection of the data lies on the first coordinate (principal component), the second greatest variance on the second coordinate, and so on. This helps in reducing the number of features while preserving as much variance (information) as possible.\n",
    "\n",
    "**Steps:**\n",
    "1. **Standardize Data:** Center and scale the data.\n",
    "2. **Compute Covariance Matrix:** Measure how features vary together.\n",
    "3. **Calculate Eigenvalues and Eigenvectors:** Find principal components (directions of maximum variance).\n",
    "4. **Sort and Select Components:** Choose top k components to reduce dimensions.\n",
    "\n",
    "**Example:**\n",
    "Suppose you have a dataset with two features, height and weight. After applying PCA:\n",
    "1. **Original Data:** Height and weight.\n",
    "2. **PCA Transformation:** Projects the data onto a new axis where the first principal component might be a combination of height and weight that captures the most variance.\n",
    "3. **Reduced Data:** You could reduce from two features to one principal component while preserving most of the original variance.\n",
    "\n",
    "PCA helps in simplifying models and improving computational efficiency by reducing the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98834442-0106-4072-ad4b-c49bc6326d55",
   "metadata": {},
   "source": [
    "Q4. What is the relationship between PCA and Feature Extraction, and how can PCA be used for Feature\n",
    "Extraction? Provide an example to illustrate this concept.\n",
    "\n",
    "PCA and feature extraction are closely related; PCA is a method of feature extraction. Feature extraction involves transforming the original features into a set of new features (or components) that capture the most important information, often by reducing dimensionality.\n",
    "\n",
    "**Using PCA for Feature Extraction:**\n",
    "1. **Transform Features:** PCA identifies principal components that capture the most variance in the data.\n",
    "2. **Select Components:** Use the top k principal components as new features.\n",
    "\n",
    "**Example:**\n",
    "Suppose you have a dataset with 5 features. After applying PCA:\n",
    "1. **Compute Principal Components:** PCA identifies new features (principal components) that combine the original features.\n",
    "2. **Select Top Components:** You might find that 2 principal components capture most of the variance.\n",
    "\n",
    "**Original Features:** [Feature1, Feature2, Feature3, Feature4, Feature5]\n",
    "\n",
    "**New Features (Principal Components):** [PC1, PC2]\n",
    "\n",
    "By selecting the top 2 principal components, you reduce the feature space from 5 dimensions to 2 dimensions, making it easier to visualize and analyze while retaining most of the original information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e54011c-e25c-490e-b651-3f84a31a32e2",
   "metadata": {},
   "source": [
    "Q5. You are working on a project to build a recommendation system for a food delivery service. The dataset\n",
    "contains features such as price, rating, and delivery time. Explain how you would use Min-Max scaling to\n",
    "preprocess the data.\n",
    "\n",
    "To preprocess the data for your recommendation system using Min-Max scaling:\n",
    "\n",
    "1. **Identify Features:** Select features such as price, rating, and delivery time.\n",
    "\n",
    "2. **Calculate Min and Max:** For each feature, determine the minimum and maximum values.\n",
    "\n",
    "3. **Apply Min-Max Scaling:** Transform each feature value to a range of [0, 1] using the formula:\n",
    "   \\[\n",
    "   X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}\n",
    "   \\]\n",
    "   where \\( X \\) is the original feature value, \\( X_{\\text{min}} \\) is the minimum value, and \\( X_{\\text{max}} \\) is the maximum value.\n",
    "\n",
    "**Example:**\n",
    "- **Price:** Original range [10, 50]. Scaled range [0, 1].\n",
    "- **Rating:** Original range [1, 5]. Scaled range [0, 1].\n",
    "- **Delivery Time:** Original range [15, 60]. Scaled range [0, 1].\n",
    "\n",
    "Scaling these features ensures that they contribute equally to the recommendation system without being biased by their original scales."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d370bfbe-fad7-4c84-8cc0-85e0e388cd4e",
   "metadata": {},
   "source": [
    "Q6. You are working on a project to build a model to predict stock prices. The dataset contains many\n",
    "features, such as company financial data and market trends. Explain how you would use PCA to reduce the\n",
    "dimensionality of the dataset.\n",
    "\n",
    "To use PCA for reducing the dimensionality of your stock price prediction dataset:\n",
    "\n",
    "1. **Standardize Data:** Normalize features (company financial data, market trends) to have a mean of 0 and a standard deviation of 1.\n",
    "\n",
    "2. **Compute Covariance Matrix:** Calculate how features vary together.\n",
    "\n",
    "3. **Calculate Eigenvalues and Eigenvectors:** Find principal components (directions of maximum variance) from the covariance matrix.\n",
    "\n",
    "4. **Sort and Select Components:** Choose the top k principal components that capture the most variance.\n",
    "\n",
    "5. **Transform Data:** Project the original data onto these top k principal components to create a reduced feature set.\n",
    "\n",
    "**Example:**\n",
    "- **Original Features:** [Feature1, Feature2, ..., FeatureN]\n",
    "- **Reduced Features (Principal Components):** [PC1, PC2, ..., PCk]\n",
    "\n",
    "By reducing to k principal components, you simplify the dataset while retaining most of the variance, making it easier to model and analyze stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3216570d-686a-4e8a-96d2-c1142bfcd054",
   "metadata": {},
   "source": [
    "Q7. For a dataset containing the following values: [1, 5, 10, 15, 20], perform Min-Max scaling to transform the\n",
    "values to a range of -1 to 1.\n",
    "\n",
    "To perform Min-Max scaling to transform the values from [1, 5, 10, 15, 20] to a range of [-1, 1]:\n",
    "\n",
    "1. **Identify Min and Max:**\n",
    "   - \\(X_{\\text{min}} = 1\\)\n",
    "   - \\(X_{\\text{max}} = 20\\)\n",
    "\n",
    "2. **Apply Scaling Formula:**\n",
    "   \\[\n",
    "   X_{\\text{scaled}} = 2 \\times \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}} - 1\n",
    "   \\]\n",
    "\n",
    "3. **Transform Each Value:**\n",
    "\n",
    "   - For \\(X = 1\\):\n",
    "     \\[\n",
    "     \\frac{1 - 1}{20 - 1} = 0 \\quad \\text{so} \\quad 2 \\times 0 - 1 = -1\n",
    "     \\]\n",
    "   - For \\(X = 5\\):\n",
    "     \\[\n",
    "     \\frac{5 - 1}{20 - 1} = \\frac{4}{19} \\approx 0.211 \\quad \\text{so} \\quad 2 \\times 0.211 - 1 \\approx -0.578\n",
    "     \\]\n",
    "   - For \\(X = 10\\):\n",
    "     \\[\n",
    "     \\frac{10 - 1}{20 - 1} = \\frac{9}{19} \\approx 0.474 \\quad \\text{so} \\quad 2 \\times 0.474 - 1 \\approx -0.052\n",
    "     \\]\n",
    "   - For \\(X = 15\\):\n",
    "     \\[\n",
    "     \\frac{15 - 1}{20 - 1} = \\frac{14}{19} \\approx 0.737 \\quad \\text{so} \\quad 2 \\times 0.737 - 1 \\approx 0.474\n",
    "     \\]\n",
    "   - For \\(X = 20\\):\n",
    "     \\[\n",
    "     \\frac{20 - 1}{20 - 1} = 1 \\quad \\text{so} \\quad 2 \\times 1 - 1 = 1\n",
    "     \\]\n",
    "\n",
    "**Scaled Values:** [-1, -0.578, -0.052, 0.474, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93813aba-1d08-4fce-8925-5e482cc5c7b2",
   "metadata": {},
   "source": [
    "Q8. For a dataset containing the following features: [height, weight, age, gender, blood pressure], perform\n",
    "Feature Extraction using PCA. How many principal components would you choose to retain, and why?\n",
    "\n",
    "To perform Feature Extraction using PCA:\n",
    "\n",
    "1. **Standardize Data:** Normalize height, weight, age, and blood pressure. Encode gender if necessary.\n",
    "\n",
    "2. **Compute PCA:** Calculate the principal components.\n",
    "\n",
    "3. **Determine Number of Components to Retain:**\n",
    "   - **Analyze Explained Variance:** Look at the explained variance ratio of each principal component.\n",
    "   - **Choose Components:** Retain enough principal components to explain a significant amount of variance, typically 80-95%.\n",
    "\n",
    "**Example Decision:**\n",
    "- If the first 3 principal components explain 90% of the variance, you would retain 3 components.\n",
    "\n",
    "**Reason:** Retaining enough components to capture the majority of the data's variance helps in reducing dimensionality while preserving the essential information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca0c90e-7f13-4c53-90cd-e594c62bb880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
